# HumorHawk at SemEval-2017 Task 6: Mixing Meaning and Sound for Humor Recognition

在给定的两条Twitter消息中确定哪一条更有趣。使用语义信息（CNN）、语音信息（LSTM）、基于特征的XGBoos, 融合这三个模型。

#### Author

- **AuthorName**: Organization

#### Abstract

This paper describes the winning system for SemEval-2017 Task 6: #HashtagWars: Learning a Sense of Humor. Humor detection has up until now been predominantly addressed using feature-based approaches. Our system utilizes recurrent deep learning methods with dense embeddings to predict humorous tweets from the @midnight show #HashtagWars. In order to include both meaning and sound in the analysis, GloVe embeddings are combined with a novel phonetic representation to serve as input to an LSTM component. The output is combined with a character-based CNN model, and an XGBoost component in an ensemble model which achieved 0.675 accuracy in the official task evaluation.

> ### Overview
>
> **Model Name**:
>
> - Ensemble Model (ENSEMBLE)融合多种模型
>
> **Motivation**:
>
> - 在SemEval-2017 Task 6 “#HashtagWars: Learning a Sense of Humor”中的子任务A(比较两条文本幽默度)，取得了第一
>
> **Structure**:
>
> - Character-to-Phoneme Model (C2P)
> - Embedding Humor Model (EHM)
> - Character Humor Model (CHM)
> - Embedding/Character Joint Model (ECJM)
> - XGBoost Feature-Based Model (XGBM)
> - Ensemble Model (ENSEMBLE)
>
> **Method**:
>
> - 构建了语音特征的模型
> - 提取了幽默特征
> - 使用字母特征的模型
>
> **Experiment**:
>
> - 在子任务A上提交结果为第一
>
> **Brief Comment**:
>
> - 构建了用于提取不同特征的模型，并进行融合，来判断文本的幽默度

<!-- ATTENTION! BE SURE TO ENSURE THE AVAILABILITY OF YOUR NOTES -->

### Introduction
To boost prediction performance further, we built an ensemble model over different model configurations. In addition to the model above, we provided an embedding-LSTM-only model and a character-CNN-only model as input to the ensemble. Inspired by previous work in NLP, we added an XGBoost feature-based model as input to the ensemble. This system was our second submission. The predictions of the ensemble model achieved 67.5% accuracy, placing it first in the official rankings for the task.
\
We also report experiments we conducted after the release of the test data, in which a few of the bugs present in the original submissions were addressed, and in which the best model achieves the accuracy of 68.3%.

### Previous Work
The majority of attempts at humor detection, including those listed above, rely on handengineered features to distinguish humor from non-humor. However, recently deep learning strategies have also been employed. Chen and Lee (2017) used convolutional networks to make predictions on humorous/non-humorous sentences in a TED talk corpus. Bertero and Fung (2016) predicted punchlines using textual and audio features from the popular sitcom The Big Bang Theory. While feature-based solutions use linguistic properties of text to detect humour, our hope in experimenting with deep learning models for this task was that they could capture such properties in a more unstructured form, without pre-determined hand-engineered indicators.

### System Description
- **Character-to-Phoneme Model (C2P)**
To give the model a representation of sound (i.e., pronunciation) for each word, we train an encoder-decoder LSTM model to convert a sequence of characters (via learned character embeddings) into a sequence of phonemes. Much like other sequence-to-sequence models, our model learns how to convert an English word into a sequence of phonemes that determine how that word is pronounced (see Figure 1).
    <div align="center">
        <image src="./img/1.png" width="700">
    </div>
    We train and evaluate this model on the CMU Pronouncing Dictionary corpus (Lenzo, 2017), which contains mappings from each word to its corresponding phonemes. We use a 0.6/0.4 traintest split. Once the model is trained, we extract the intermediate embedding state (200 dim) between the encoder and decoder; this acts as a phonetic embedding, containing all information needed to pronounce the word. The resulting phonetic embedding for each word is concatenated with a semantic embedding to serve as the input for the embedding humor model (see below). Table 1 shows sample output of the model.
    <div align="center">
        <image src="./img/2.png" width="700">
    </div>
- **Embedding Humor Model (EHM)**
For both tweets in a tweet pair, a concatenation of a GloVe word embedding (Pennington et al., 2014) and phonetic embedding is processed by an LSTM encoder at each time-step (per word). We use word embeddings pre-trained on a Twitter corpus, available on the GloVe website1. Zero padding is added to the end of each tweet for a maximum length of 20 words/tweet. The output of each LSTM encoder (800 dim) is inserted into dense layers, and a binary classification decision is generated.

- **Character Humor Model (CHM)**
The character-based humor model processes each tweet as a sequence of characters with a CNN (Koushik, 2016). 30-dimensional embeddings are learned per character as input. The output of the CNN for both tweets in the pair are inserted into dense layers.

- **XGBoost Feature-Based Model (XGBM)**
    - 1. Sentiment of each tweet in a pair, obtained with TwitterHawk, a state-of-the-art sentiment analysis system for Twitter (Boag et al., 2015).
    - 2. Sentiment of the tokenized hashtag.
    - 3. Length of each tweet in both tokens and characters (a very long tweet might not be funny)
    - 4. Distance of the average GloVe embeddings of the tokens of the tweets to the global centroid of the embeddings of all tweets for the given hashtag.
    - 5. Minimum, maximum and average distance from each token in a tweet to the hashtag.
    - 6. Number of tokens belonging to the top-10 most frequent POS tags on the training data.

- **Embedding/Character Joint Model (ECJM)**
The output of the embedding model LSTM encoders and the character model CNN encoders are fed into dense layers. For encoder input $N$, the three dense layers are of size $(3/4)N, (1/2)N,$ and $1.$ Each layer gradually reduces dimensionality to final binary decision.

- **Ensemble Model (ENSEMBLE)**
Inspired by the success of ensemble models in other tasks (Potash et al., 2016a; Rychalska et al., 2016) we built an ensemble model that combines the predictions of the character-based model, embedding-based model, the character/embedding joint humor model, and the feature-based XGBoost model to make the final prediction which incorporates different views of the input data. For the ensemble model itself, we use an XGBoost model again. Input predictions are obtained by using 5-fold cross-validation on the training data.

### Experiment
<div align="center">
    <image src="./img/3.png" width="700">
</div>
