# Predicting Audience’s Laughter Using Convolutional Neural Network

识别演讲者的幽默（TED Talk），传统模型（语义结构特征&语义距离特征）、CNN。

#### Author

- **Lei Chen, Chong Min Lee**: Educational Testing Service (ETS)

#### Abstract

For the purpose of automatically evaluating speakers’ humor usage, we build a presentation corpus containing humorous utterances based on TED talks. Compared to previous data resources supporting humor recognition research, ours has several advantages, including (a) both positive and negative instances coming from a homogeneous data set, (b) containing a large number of speakers, and (c) being open. Focusing on using lexical cues for humor recognition, we systematically compare a newly emerging text classification method based on Convolutional Neural Networks (CNNs) with a well-established conventional method using linguistic knowledge. The advantages of the CNN method are both getting higher detection accuracies and being able to learn essential features automatically.

> ### Overview
>
> **Model Name**:
>
> - CNN
>
> **Motivation**:
>
> - 使用CNN模型来对TED进行分类
>
> **Structure**:
>
> - CNN
>
> **Method**:
>
> - 设置了Context窗口大小，取幽默对话的前7句话和后7句话
>
> **Experiment**:
>
> - 在TED数据集上取得了不错的效果
>
> **Brief Comment**:
>
> - 定义了上下文的窗口，通过选取前7句话和后7句话，来保证整体的话题转变不大，保证模型在训练过程中不会出现话题的巨大转变

<!-- ATTENTION! BE SURE TO ENSURE THE AVAILABILITY OF YOUR NOTES -->

### Introduction
Automatically simulating an audience’s reactions to humor will not only be useful for presentation training, but also improve conversational systems by giving machines more empathetic power. The present study reports our efforts in recognizing utterances that cause laughter in presentations. These include building a corpus from TED talks and using Convolutional Neural Networks (CNNs) in the recognition.

### Related Work
From the brief review, it is clear that corpora used in humor research so far are limited to oneline puns or jokes and conversations from TV comedy shows. There is a great need for an open corpus that can support investigating humor in presentations. CNN-based text categorization methods have been applied to humor recognition (e.g., in (Bertero and Fung, 2016b)) but with limitations: (a) a rigorous comparison with the stateof-the-art conventional method examined in Yang et al. (2015) is missing; (b) CNN’s performance in the previous research is not quite clear; and (c) some important techniques that can improve CNN performance (e.g., using varied-sized filters and dropout regularization (Hinton et al., 2012)) were not applied. Therefore, the present study is meant to address these limitations.

### TED Talk Data
We collected 1,192 TED Talk transcripts. An example transcription is given in Figure 1. The collected transcripts were split into sentences using the Stanford CoreNLP tool (Manning et al., 2014). In this study, sentences containing or immediately followed by ‘(Laughter)’ were used as ‘Laughter’ sentences, as shown in Figure 1; all other sentences were defined as ‘No-Laughter’ sentences. Following Mihalcea and Strapparava (2005) and Yang et al. (2015), we selected the same numbers (n = 4726) of ‘Laughter’ and ‘No-Laughter’ sentences. To minimize possible topic shifts between positive and negative instances, for each positive instance, we picked one negative instance nearby (the context window was 7 sentences in this study). For example, in Figure 1, a negative instance (corresponding to ‘sent-2’) was selected from the nearby sentences ranging from ‘sent-7’ to ‘sent+7’.(sent=sentence)
<div align="center">
    <image src="img/1.png" width="700">
</div>

### Methodology
<div align="center">
    <image src="img/2.png" width="700">
</div>

### Experiment
<div align="center">
    <image src="img/3.png" width="700">
</div>
