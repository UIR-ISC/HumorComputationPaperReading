# “The Boating Store Had Its Best Sail Ever”: Pronunciation-attentive Contextualized Pun Recognition

识别出句子中的双关语，PCPR(Pronunciation-attentive Contextualized Pun Recognition)通过捕捉周围语境与其对应的语音符号之间的关联，导出句子中每个单词的语境化表示，来进行双关语识别。

#### Author

- **Yichao Zhou, Jyun-yu Jiang, Jieyu Zhao, Kai-Wei Chang and Wei Wang**: Computer Science Department, University of California

#### Abstract

Humor plays an important role in human languages and it is essential to model humor when building intelligence systems. Among different forms of humor, puns perform wordplay for humorous effects by employing words with double entendre and high phonetic similarity. However, identifying and modeling puns are challenging as puns usually involved implicit semantic or phonological tricks. In this paper, we propose Pronunciation-attentive Contextualized Pun Recognition (PCPR) to perceive human humor, detect if a sentence contains puns and locate them in the sentence. PCPR derives contextualized representation for each word in a sentence by capturing the association between the surrounding context and its corresponding phonetic symbols. Extensive experiments are conducted on two benchmark datasets. Results demonstrate that the proposed approach significantly outperforms the state-of-the-art methods in pun detection and location tasks. In-depth analyses verify the effectiveness and robustness of **PCPR**.

> ### Overview
>
> **Model Name**:
>
> - PCPR(Pronunciation-attentive Contextualized Pun Recognition)
>
> **Motivation**:
>
> - 构建英文音标向量来提取语音特征
>
> **Structure**:
>
> - BERT+语音注意力
>
> **Method**:
>
> - Self-Attention
>
> **Experiment**:
>
> - 最终在Pun数据集上取得了不错的效果
>
> **Brief Comment**:
>
> - 提出了构建音标向量提取语音特征的方法

<!-- ATTENTION! BE SURE TO ENSURE THE AVAILABILITY OF YOUR NOTES -->

### Introduction
In this paper, we propose Pronunciation-attentive Contextualized Pun Recognition (PCPR) to jointly model the contextualized word embeddings and phonological word representations for pun recognition. To capture the phonological structures of words, we break each word into a sequence of phonemes as its pronunciation so that homophones can have similar phoneme sets. For instance, the phonemes of the word *pun* are {P, AH, N}. In PCPR, we construct a pronunciation attentive module to identify important phonemes of each word, which can be applied in other tasks related to phonology. We jointly encode the contextual and phonological features into a self-attentive embedding to tackle both pun detection and location tasks. We summarize our contributions as following.
- To the best of our knowledge, PCPR is the first work to jointly model contextualized word embeddings and pronunciation embeddings to recognize puns. Both contexts and phonological properties are beneficial to pun recognition.
- Extensive experiments are conducted on two benchmark datasets. PCPR significantly outperforms existing methods in both pun detection and pun location. In-depth analyses also verify the effectiveness and robustness of PCPR.
- We release our implementations and pre-trained phoneme embeddings at https://github.com/joey1993/pun-recognition to facilitate future research.

### Related Work
- **Pun Recognition and Generation**
However, all these methods only make use of limited context information. Other than the pun recognition, Yu et al. (2018) generate homographic puns without requiring any pun data for training. He et al. (2019) improve the homographic pun generation based on the “local-global surprisal principle” which posits that the pun word and the alternative word have a strong association with the distant and immediate context respectively.
- **Pronunciation Embeddings**
However, these pronunciation embeddings are word-level features, while in our approach, we make use of syllabic pronunciations which is phoneme-level and could help with the out-of-vocabulary (OOV) situation. Luo et al. (2019) also propose an adversarial generative network for pun generation, which does not require any pun corpus.
- **Contextualized Word Embeddings**
McCann et al. (2017) combine the pivot word embeddings as well as the contextual embeddings generated by an encoder from a supervised neural machine translation task. Peters et al. (2017) enrich the word embeddings by the contextual information extracted from a bidirectional language model. (Devlin et al., 2018) learn the language embedding by stacking multiple transformer layers with masked language model objective which advances the state-of-the-art for many NLP tasks. Yang et al. (2019) enable learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and solve the problem of pretrain-finetune discrepancy.

### Pronunciation-attentive Contextualized Pun Recognition(PCPR)
- **Problem Statement**
Suppose the input text consists of a sequence of $N$ words $\{w_1, w_2, ..., w_N\}$. For each word wi with Mi phonemes in its pronunciation, the phonemes are denoted as $R(w_i) = \{r_{i, 1}, r_{i,2}, ..., r_{i, M_i}\}$, where $r_{i,j}$ is the $j$-th phoneme in the pronunciation of $w_i$. These phonemes are given by a dictionary. In this paper, we aim to recognize potential puns in the text with two tasks, including pun detection and pun location, as described in the following.
\
**Task 1: Pun Detection.** The pun detection task identifies whether a sentence contains a pun. Formally, the task is modeled as a classification problem with binary label $y^D$.
\
**Task 2: Pun Location.** Given a sentence containing at least a pun, the pun location task aims to unearth the pun word. More precisely, for each word $w_i$, we would like to predict a binary label $y^L_i$ that indicates if $w_i$ is a pun word. 
\
In addition to independently solving the above two tasks, the ultimate goal of pun recognition is to build a pipeline from scratch to detect and then locate the puns in texts. Hence, we also evaluate the end-to-end performance by aggregating the solutions for two tasks.
- **Framework Overview**
<div align="center">
    <image src="img/1.png" width="700">
</div>

- **ContextualizedWord Embeddings**
BERT deploys a multi-layer bidirectional encoder based on transformers with multi-head selfattention (Vaswani et al., 2017) to model words in the text after integrating both word and position embeddings (Sukhbaatar et al., 2015). As a result, for each word, a representative contextualized embedding is derived by considering both the specific word and all contexts in the document. Here we denote $T^C_i$ as the $d_C$-dimensional contextualized word embedding for the word $w_i$. In addition, BERT contains a special token [CLS] with an embedding vector in BERT to represent the semantics of the whole input text.
- **Pronunciation Embeddings**
To learn the phonological characteristics of words, PCPR models the word phonemes. For each phoneme $r_{i, j}$ of the word $w_i$, we project $r_{i, j}$ to a $d_P$-dimensional embedding space as a trainable vector $u_{i, j}$ to represent its phonological properties. 
Based on the phoneme embeddings of a word, we apply the attention mechanism (Bahdanau et al., 2015) to simultaneously identify important phonemes and derive the pronunciation embedding $T^P_i$. Specifically, the phoneme embeddings are transformed by a fully-connected hidden layer to measure the importance scores $\alpha^P_i$ as follows:
    
$$ v_{i, j}=tanh(\mathcal{F}_P(u_{i,j})) $$
    
$$ \alpha^P_{i,j}=\frac{v^T_{i,j}v_{S}}{\sum_{k}v^T_{i,k}v_S} $$
    
where $\mathcal{F}_P(·)$ is a fully-connected layer with $d_A$ outputs and $d_A$ is the attention size; vs is a $d_A$-dimensional context vector that estimates the importance score of each pronunciation embedding. Finally, the pronunciation embeddings $T^P_i$ can be represented as the weighted combination of phoneme embeddings as follows:
    
$$ T_i^P=\sum_{j}\alpha_{i,j}u_{i,j} $$
    
Moreover, we can further derive the joint embedding $T^J_i$ to indicate both word semantics and phonological knowledge for the word $w_i$ by concatenating two different embeddings as follows:
    
$$ T_i^J=[T_i^C;T^P_i] $$
    
Note that the joint embeddings are $d_J$-dimensional vectors, where $d_J = d_C + d_P$.
- **Pronunciation-attentive Contextualized Embedding with Self-attention**
For the task of pun detection, understanding the meaning of input text is essential. Due to its advantages of interpretability over convolutional neural network (LeCun et al., 1995) and recurrent neural network (Schuster and Paliwal, 1997), we deploy the self-attention mechanism (Vaswani et al., 2017) to capture the overall semantics represented in the joint embeddings. For each word $w_i$, the self-attention mechanism estimates an importance vector $\alpha^S_i$:
    
$$ \mathcal{F}_S(T)=Softmax(\frac{TT^T}{\sqrt{d}})T $$
    
$$ \alpha_i^S=\frac{exp(\mathcal{F}_S(T_i^J))}{\sum_jexp(\mathcal{F}_S(T_j^J))} $$
    
where $\mathcal{F}_S(·)\$ is the function to estimate the attention for queries, and $d$ is a scaling factor to avoid extremely small gradients. Hence, the self-attentive embedding vector is computed by aggregating joint embeddings:
    
$$ T^j_{[ATT]}=\sum_i\alpha_i^{S}\cdot{T}_i^J $$
    
Note that the knowledge of pronunciations is considered by the self-attentive encoder but not the contextualized word encoder. Finally, the pronunciation-attentive contextualized representation for the whole input text can be derived by concatenating the overall contextualized embedding and the self-attentive embedding:
    
$$ T^J_{[CLS]}=[T^C_{[CLS]};T^J_{[ATT]}] $$
    
Moreover, each word $w_i$ is benefited from the selfattentive encoder and is represented by a joint embedding:
    
$$ T^J_{i,[ATT]}=\alpha_i^S\cdot T_i^J $$
    
- **Inference and Optimization**
    - **Pun Detection**
    Pun detection is modeled as a binary classification task. Given the overall embedding for the input text $T^J_{[CLS]}$, the prediction $\hat y_D$ is generated by a fully-connected layer and the softmax function:
    
    $$ \hat y^D=\mathop{argmax}\limits_{k\in\{0,1\}}\mathcal F_D(T^J_{[CLS]})_k $$
    
    - **Pun Location**
    For each word wi, the corresponding self-attentive joint embedding $T^J_{i,[ATT]}$ is applied as features for pun location. Similar to pun detection, the prediction $\hat y^L_i$ is generated by:
    $$ \hat y^L_i=\mathop{argmax}\limits_{k\in\{0,1\}}\mathcal F_L(T^J_{i,[ATT]})_k $$
    where $\mathcal F_L(·)$ derives two logits for classifying if a word is a pun word. 
    Since both tasks focus on binary classification, we optimize the model with cross-entropy loss.

### Experiment
- **Pun location performance over different $d_P$&$d_A$**
<div align="center">
    <image src="img/2.png" width="700">
</div>

- **Results**
<div align="center">
    <image src="img/3.png" width="700">
</div>
<div align="center">
    <image src="img/4.png" width="700">
</div>
<div align="center">
    <image src="img/5.png" width="700">
</div>

- **Ablation Study**
<div align="center">
    <image src="img/6.png" width="700">
</div>

- **AttentiveWeights Interpretation**
<div align="center">
    <image src="img/7.png" width="700">
</div>

- **Sensitivity to Text Lengths**
<div align="center">
    <image src="img/8.png" width="700">
</div>
