# Making Computers Laugh: Investigations in Automatic Humor Recognition

基于幽默文体特征和文本内容来判断短笑话是否幽默。

#### Author

- **Rada Mihalcea:** Department of Computer Science University of North Texas Denton
- **Carlo Strapparava:** Istituto per la Ricerca Scientifica e Tecnologica

#### Abstract

Humor is one of the most interesting and puzzling aspects of human behavior. Despite the attention it has received in fields such as philosophy, linguistics, and psychology, there have been only few attempts to create computational models for humor recognition or generation. In this paper, we bring empirical evidence that computational approaches can be successfully applied to the task of humor recognition. Through experiments performed on very large data sets, we show that automatic classification techniques can be effectively used to distinguish between humorous and non-humorous texts, with significant improvements observed over apriori known baselines.

> ### Overview
>
> **Model Name**:
>
> - 朴素贝叶斯&SVM
>
> **Motivation**:
>
> - 将幽默识别问题看作传统分类任务，并使用分类器对文本分类
>
> **Structure**:
>
> - 结合幽默特征的朴素贝叶斯&SVM
>
> **Method**:
>
> - 对幽默文本特征进行量化以及模型(朴素贝叶斯&SVM)特征，特征如下：
>   - Humor-Specific Stylistic Features:
>       - Alliteration
>       - Antonymy
>       - Adult slang
>   - Content features
>       - Naive Bayes
>       - SVM
>
> **Experiment**:
>
> - 在本文提出的数据集基础上取得了不错的效果
>
> **Brief Comment**:
>
> - 通过对幽默文本特征，进行量化输入模型

<!-- ATTENTION! BE SURE TO ENSURE THE AVAILABILITY OF YOUR NOTES -->

### Introduction
We attempt to formulate the humor-recognitionproblem as a traditional classification task, and feed positive (humorous) and negative (non-humorous) examples to an automatic classifier. The humorous data set consists of one-liners collected from the Web using an automatic bootstrapping process. The non-humorous data is selected such that it is structurally and stylistically similar to the oneliners. Specifically, we use three different negative data sets: (1) Reuters news titles; (2) proverbs; and (3) sentences from the British National Corpus (BNC). The classification results are encouraging, with accuracy figures ranging from 79.15% (Oneliners/BNC) to 96.95% (One-liners/Reuters). Regardless of the non-humorous data set playing the role of negative examples, the performance of the automatically learned humor-recognizer is always significantly better than apriori known baselines.

The remainder of the paper is organized as follows.We first describe the humorous and nonhumorous data sets, and provide details on the Webbased bootstrapping process used to build a very large collection of one-liners. We then show experimental results obtained on these data sets using several heuristics and two different text classifiers. Finally, we conclude with a discussion and directions for future work.

### Datasets
- Humorous Data:
    - *One-liners*
- Non-humorous Data
    - *Reuters titles*
    - *BNC(British National Corpus)*
    - *Proverbs*
- Datasets：
<div align="center">
  <image src="./img/1.png" width="700">
</div>

### Methodology
- Humor-Specific Stylistic Features
    - Alliteration
        To extract this feature, we identify and count the number of alliteration/rhyme chains in each example in our data set. The chains are automatically extracted using an index created on top of the CMU pronunciation dictionary.
    - Antonymy
        The lexical resource we use to identify antonyms is WORDNET (Miller, 1995), and in particular the antonymy relation among nouns, verbs, adjectives and adverbs. For adjectives we also consider an indirect antonymy via the similar-to relation among adjective synsets. Despite the relatively large number of antonymy relations defined in WORDNET, its coverage is far from complete, and thus the antonymy feature cannot always be identified. A deeper semantic analysis of the text, such as word sense disambiguation or domain disambiguation, could probably help detecting other types of semantic opposition, and we plan to exploit these techniques in future work.
    - Adult slang
        To form a lexicon required for the identification of this feature, we extract from WORDNET DOMAINS all the synsets labeled with the domain SEXUALITY. The list is further processed by removing all words with high polysemy $(\geq4)$. Next, we check for the presence of the words in this lexicon in each sentence in the corpus, and annotate them accordingly. Note that, as in the case of antonymy, WORDNET coverage is not complete, and the adult slang feature cannot always be identified.
- Content Feature
    - Naive Bayes
        The main idea in a Naive Bayes text classifier is to estimate the probability of a category given a document using joint probabilities of words and documents. Naive Bayes classifiers assume word independence, but despite this simplification, they perform well on text classification. While there are several versions of Naive Bayes classifiers (variations of multinomial and multivariate Bernoulli), we use the multinomial model, previously shown to be more effective (McCallum and Nigam, 1998).
    - SVM
        Support Vector Machines (SVM) are binary classifiers that seek to find the hyperplane that best separates a set of positive examples from a set of negative examples, with maximum margin. Applications of SVM classifiers to text categorization led to some of the best results reported in the literature (Joachims, 1998).       

### Experiment

- Humor-specific Features
<div align="center">
  <image src="img/2.png" width="700">
</div>

- Content Features
<div align="center">
  <image src="img/3.png" width="700">
</div>

- Combining Stylistic and Content Features
<div align="center">
  <image src="img/4.png" width="700">
</div>
