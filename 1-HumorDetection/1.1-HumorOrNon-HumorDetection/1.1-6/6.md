# Identifying Humor in Reviews using Background Text Sources

利用背景知识（维基百科）结合不一致论建模，提出了生成语言模型，来识别评论中的幽默。

#### Author

- **Alex Morales and ChengXiang Zhai**: Department of Computer Science, University of Illinois

#### Abstract
We study the problem of automatically identifying humorous text from a new kind of text data, i.e., online reviews. We propose a generative language model, based on the theory of incongruity, to model humorous text, which allows us to leverage background text sources, such as Wikipedia entry descriptions, and enables construction of multiple features for identifying humorous reviews. Evaluation of these features using supervised learning for classifying reviews into humorous and non-humorous reviews shows that the features constructed based on the proposed generative model are much more effective than the major features proposed in the existing literature, allowing us to achieve almost 86% accuracy. These humorous review predictions can also supply good indicators for identifying helpful reviews.

> ### Overview
>
> **Model Name**:
>
> - 利用生成模型来对幽默文本分类
>
> **Motivation**:
>
> - 通过生成模型来提取不协调特征来实现幽默识别
>
> **Structure**:
>
> - 类似于LDA的生成模型
>
> **Method**:
>
> - 构建了大量的特征
>
> **Experiment**:
>
> - 对比不同特征对分类结果的影响
>
> **Brief Comment**:
>
> - 提出了很多特征的构建方法，并进行了对比实验，来验证特征对分类结果的影响

<!-- ATTENTION! BE SURE TO ENSURE THE AVAILABILITY OF YOUR NOTES -->

### Introduction
Specifically, we propose a general generative language model to model the generation of humorous text. The proposed model is a mixture model with multinomial distributions as component models (i.e., models of topics), similar to Probabilistic Latent Semantic Analysis (Hofmann, 1999). However, the main difference is that the component word distributions (i.e., component language models) are all assumed to be known in our model, and they are designed to model the two types of language used in a humorous text, including 1) the general background model estimated using all the reviews, and 2) the reference language models of all the topical aspects covered in the review that capture the typical words used when each of the covered aspects is discussed. Thus the model only has the parameters indicating the relative coverage of these component language models. The idea here is to use these parameters to assess how well a review can be explained by collectively by the reference language models corresponding to all the topical aspects covered in the review, which are estimated using an external text source (e.g., Wikipedia).

We construct multiple features based on the generative model and evaluate them using supervised learning for classifying reviews into humorous and non-humorous reviews. Experiment results on a Yelp review data set show that the features constructed based on the proposed generative model are much more effective than the major features proposed in the existing literature, allowing us to achieve almost 86% accuracy. We also experimented with using the results of humorous review prediction to further predict helpful reviews, and the results show that humorous review prediction can supply good indicators for identifying helpful reviews for consumers.

### Referential Humor and Incongruity
In Figure 1, we show a humorous review, randomly sampled by using our classifier with a high probability of being funny, where the reviewer asserts that the food has extreme medicinal properties. The reviewer refers to “Nyquil” a common cold medicine to express the food’s incredible ability to cure ailments. This appears almost surprising since it would not normally be mentioned in restaurants reviews. To identify the intended humor, we can use the references the reviewer makes, e.g. Nyquil, as clues to what she is emphasising, e.g. the savory soondubu, by making such comparisons, e.g. the heavenly taste and amazing price. Yelp users seem to consider funny reviews which tended to deviate from what was expected into things which would seem out of place.
<div align="center">
    <image src="img/1.png" width="700">
</div>

### Language Models as a Proxy for Incongruity
We now describe the proposed model in more detail. Suppose we observe the following references to $K_d$ topical aspects $A_d = \{r_1, r_2, ..., r_{K_d}\}$ in a review $R_d = [w_1,w_2, ...,w_{N_d}]$, where each $r_i$ corresponds to an aspect reference (i.e. NyQuil in our running example), and $w_i\in{V}$ , where $V$ is the vocabulary set. The model generates a word, for some review, at a time, which talks about a specific aspect or is related to the language used in Yelp more broadly; we call the latter the background language model. Thus a word is generated from a mixture model, and its probability is an interpolation of the background language and the language of the references as shown in Figure 2.

<div align="center">
    <image src="img/2.png" width="700">
</div>

These aspects provide some context to the underling meaning of a review; the reviewers use these aspects for creative writing when describing their dining experience. These aspects allow us to use external information as the context, thus we develop measures for incongruity addressing the juxtaposition of the aspect’s context and the review. The review construction process is represented in a generative model, see Figure 2, where the shaded nodes represent our observations, we have observed the words as well as the referenced aspects which the reviewer has mentioned in their review. The light nodes are the labels for the aspect which has generated the corresponding word. Since the background language model, denoted by$\theta^B$, is review independent, we can simplify the generative model by copying the background language model for each review, thus we can focus on the parameter estimation for each review in parallel.

A key component to the success of our features is the mesh of background text from external sources, or *background text sources*, and the reviews. In our example, Figure 1, Nyquil is a critical component for understanding the humor. However it is difficult to understand some references a reviewer makes without any prior knowledge. To do so, we incorporate external background knowledge in the form of language models for the referenced aspect present in the reviews. If the reviewer has made $K_d$ references to different aspects $A_d$ in review $R_d$, then for each $r_i$ there is a corresponding language model $\theta^{r_i}_w = P(w|\theta^{r_i})$ over the vocabulary $w\in{V}$ . For simplicity, we describe the model for each document, and use the notation $\theta^i_w$ and $\theta^i$ for the corresponding language model of $r_i$.
- **Incorporating Background Text Sources**
As described before, some features we will use to describe incongruity correspond to the weights of the mixture model used to generate the words in the review, which take into account the language of the references she will make or allude, as shown in Figure 2. The probability that an author will generate a word $w$, for the $d$th review given corresponding aspects $\Theta=\{\theta^B, \theta^1, ..., \theta^{K_d}\}$, is
$$ 
P(w, d, \Theta)=\sum_{z=0}^{K_d}P(w, z, d, \Theta)=\\
\sum_{z=0}^{K_d}P(w|z,\Theta)P(z|d)=\lambda\theta_{w}^{B}+(1-\lambda)\sum_{i=1}^{K_d}\pi_{i}\theta_w^i $$
Note $K_d$ indicates the different aspects the reviewer will mention in a review, $R_d$, and hence it can vary between reviews. $\theta^B_w=P(w|z=0,\Theta)$ is the probability that the word will appear when writing a review (e.g. background language model) and $\theta^i_w$ can be interpreted as word distributions over aspect $i$. Here $\lambda=P(z = 0|d)$ is the weight for the background language model and $\pi_i = \frac{P(z = i|d)}{1-P(z = 0|d)}$ denotes the relative weights of the referenced aspect’s language models used in the review. We denote our parameters for review $R_d$ as $\Lambda_{R_d} = \{\pi_1, ..., \pi_{K_d} , \lambda\}$. Note that the parameter set varies depending on how many references the review makes. In order to estimate $P(w|\theta^i)$, we first need to find the aspects that the user is mentioning in their reviews. In general aspects can be defined as any topics explicitly defined in external background text data; in our experiments we define aspects as Wikipedia entities. In subsection 5.1, we describe one way of obtaining these aspects, but first we describe the estimation methodology.
- **Parameter Estimation**
To estimate our parameters $\Lambda_{R_d}$ , we would like to maximize the likelihood of $P(R_d)$, which is the same as maximizing the log-likelihood of $P(R_d)$.
That is

$$ \begin{split}
\hat\Lambda=&{argmax}_{\Lambda}logP(R_d|\Lambda)\\
=&{argmax}_{\Lambda}\sum_{w\in{V}}c(w,R_d)log(P(w,d,\Theta))
\end{split} $$

Here $c(w,R_d)$ represents the number of occurrences of the word $w$ in $R_d$. In order to maximize the log-likelihood we use the EM algorithm (Dempster et al., 1977), to compute the update rules for the parameters $\lambda$ and $\pi_1,...\pi_{K_d}$. For the E-Step, at the $n + 1$th iteration we have
$$ P(z_w=0)=\frac{\theta_w^{B}\lambda^{(n)}}{(\sum_{l=1}^{K_d}\theta_w^{l}\pi_l^{(n)})(1-\lambda^{(n)})+\theta_w^{B}\lambda^{(n)}} $$
$$ P(z_{w}=j)=\frac{\theta_w^{j}\pi_j^{(n)}}{\sum_{l=1}^{K_d}\theta_w^{l}\pi_l^{(n)}} $$
Where $z_w$ is a hidden variable indicating whether we have selected any of the aspect language models, or the background language model, when generating the word $w$. The update rules for the MStep are as follows:
$$ \begin{split}
&\lambda^{(n)}=\frac{\sum_{w\in{V}}c(w,R_d)P(z_{w}=0)}{n}, \pi_j^{(n)}=\\
&\frac{\sum_{w\in{V}}c(w,R_d)P(z_w=j)(1-P(z_w=0))}{\sum_{l=1}^{K_d}\sum_{w\in{V}}c(w,R_d)P(z_{w}=l)(1-P(z_w=0))}
\end{split} $$
We ran EM until the parameters converged or a small threshold was reached.

### Features construction
- **Incongruity features**
A natural feature in our incongruity model is the estimated background weight, $\lambda$, since it indicates how much emphasis the reviewer puts in their review to describe the referenced aspects, we denote this feature by **A1**. Another feature is based on the relative weights for the referenced aspect’s language models. There tends to be more ‘surprise’ in a review when the reviewer talks about multiple aspects equally, this is because the more topics the reviewer writes about the more intricate the review becomes. We use the entropy of the weights $H(R_d) = −\sum^{K_d} _{i=1}\pi_ilog\pi_i$ as another incongruity score and label this feature as **A2**.
- **Unexpectedness features**
Humor often relies on introducing concepts which seem out of place to produce a comedic effect. Thus we want to measure this divergence from the references and the language expected in the reviews. Hence a natural measure is the KL-divergence measure the distance between the background language model and the aspect language models. We use the largest deviation, $max_i\{D_{KL}(\theta^i||\theta^B)\}$ as feature **D2**. For this feature we tried different combinations such as a weighted average, but both features seemed to perform equally so we only describe one of them.
By considering the context of the references in the reviews we can distinguish which statements should be considered as humorous, thus we also use the relative weight for each aspect to measure unexpectedness. Formally we have $U_j=\pi_{j}D_{KL}(\theta^j||\theta^B)$, lastly we will denote $max_i\{U_i\}$ these set of features as **U2**.
- **Baseline features from previous work**
    - **Context features**
    Due to the popular success of context features by Mihalcea and Pulman (2007) we tried the following features content related features: **C1**: the uni-grams in the review. **C2**: length of the review. **C3**: average word length. **C4**: the ratio of uppercase and lowercase characters to other characters in the review text.
    - **Alliteration**
    Inspired by the success that Mihalcea and Strapparava (2006) had using the presence and absence of alliteration in jokes, we developed a similar feature for identifying funny reviews. We used CMU’s pronunciation dictionary to extract the pronunciation to identify alliteration chains, and rhyme chains in sentences. A chain is a consecutive set of words which have similar pronunciation, for example if the words words “scenery” and “greenery” are consecutive they would form a rhyme chain. Similarly, “vini, vidi, visa” also forms another chain this time an alliteration chain. We used the review’s total number of alliteration chains and rhyme chains and denote it by **E1**. Note that there could be different lengths of chains, we experimented with some variations but they performed roughly the same, for simplicity we did not describe them here.
    - **Ambiguity**
    Ambiguity in word interpretation has also been found to be useful in finding jokes. The reasoning is that if a word has multiple interpretation it is possible that the author intended another interpretation of the word instead of the more common one. We restricted the words in the reviews to only nouns and used Wordnet to extract the synsets for these words. Then we counted the average number of synsets for each of these words, finally we took the mean score for all the words in the reviews. We call these features lexical ambiguity and denote it by **E2**.

### Experiment
- Preliminaries and Groundtruth Construction
In Figure 3 we give an account of data statistics based on a random sample of 500,000 reviews, focusing on the funny voting judgements and the star rating distributions. In Figure 3a, we notice that on average the highly rated restaurants tend to have more reviews. Since users would prefer to dine in a restaurant expecting to get a better overall experience, they create a feedback on the reviews for those highly rated restaurants. This “rich-get-richer” effect has been also been recently observed in other social networks (Su et al., 2016) and a more detailed analysis is out of scope of this paper. We observe that most of the reviews receive a low number of funny votes in Figure 3b, with $μ = 0.55$, where $μ$ is the average funny rating. Computing the restaurant’s average funny votes, then taking the mean by the star ratings for each category range, see Figure 3c, which seems to be consistently increasing across the different star ratings. Note that this also includes the restaurants with zero funny votes, by excluding these we found that the ratings were more consistently stable on about 2.1 votes. Thus regardless of restaurant rating, the funny reviews distribution are stable on average. Considering the prevalence of noise in the voting process, we also analysed those reviews with more than one funny vote $(μ = 3.90)$, and with more than two votes $(μ = 5.54)$.
<div align="center">
    <image src="img/3.png" width="700">
</div>

- Results

<div align="center">
    <image src="img/4.png" width="700">
</div>
